
* 资料调研
  1. TF-IDF
     - 特征选择方法（基于DF, MI, IG, CHI, TS) [1]
     - DF效果与最好的IG, CHI类似，选用它做特征选择
  2. Topic Model, HTMM
     - HTMM与LDA的比较
     - HTMM的实现，OpenHTMM [2]
  3. 设计用户抑郁相似度计算
     - 取最相似微薄作为相似度
     - 取平均相似微薄作为相似度
     - 计算两个微薄序列相似度，采用动态规划算法，类似编辑距离
     - 微薄相似度采用KL距离，cos相似度计算
  4. 分词器及其效果，选用了一个开源的NlpBamboo
  5. python机器学习库scikt-learn及画图包matplotlib
     - 回归分析
     - 画图
  6. 情感词典 hownet
* 数据预处理
  1. 从数据库导出160个评分用户微薄及用户信息
  2. 简单聚类分析、回归分析，发现效果不佳
  3. 在分词前对微薄内容进行处理，包括
     - 对类似@xxx, //@xxx, [表情]预先抽取出来
     - 替换数字、日期时间、链接为DIGIT，DATE，URL
     - 去掉特殊符号，如❤, ღ, ❥, ♡
  4. 使用NlpBamboo分词
     - 对上述处理后的微薄，当作一个句子扔给NlpBamboo分词
     - 对整个语料分词后的单词编号，方便后续处理
  5. 使用窗口滑动方法每5条连续微薄合成一条长微薄
  6. 每一条长微薄当作一篇文章，扔给OpenHTMM学习出每条长微薄的主题分布
  7. 使用matplotlib画图观察主题分布
  8. 用最压抑用户的微薄跟其他用户的使用KL距离计算微薄主题分布相似度，发现不呈线性关系，是震荡的，基本放弃使用微薄相似度来代替用户抑郁相似度想法
* baseline & 我们的方法
  1. 计算用户在2012年11月份左右的微薄的TF-IDF作为特征
  2. 设计其他特征，比如用户原创/转发微薄比例，粉丝/关注比例等
  3. 抽取用户微薄熵最小的topk个主题分布作为特征
     - 尝试过用方差最大的topk个主题分布作为特在，效果没有熵最小的好
  4. 同时，预测评分0.5也作为baseline
* 使用学习器训练，画图
  1. 尝试使用svm，gradientboosting等学习器来做回归分析
  2. 参数调试
  3. 画在不同参数下效果图
* 结果分析及改进方案
  1. 在k比较小时，我们的方法比直接预测0.5的效果要好
  2. 结果溯源，找回对应微薄
  3. 从溯源的微薄看出，存在噪音（比如非情感微薄，广告微薄）
     - 去掉噪音是我们将来主要的改进方向
     - 引入情感词典来过滤非情感微薄
   


[1] Yang, Y., Pedersen J.P. A Comparative Study on Feature Selection in Text Categorization (pdf) Proceedings of the Fourteenth International Conference on Machine Learning (ICML'97), 1997, pp412-420.
[2] https://code.google.com/p/openhtmm/


